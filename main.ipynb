{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rRjvVSbuHGBA"
   },
   "outputs": [],
   "source": [
    "!pip install -q Cython contextlib2 pillow lxml matplotlib PyDrive\n",
    "\n",
    "!pip install -q pycocotools   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zHemVgt1HUEV",
    "outputId": "373f4ad0-bb88-4ae4-f343-bbb519df43bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted zip file 1-XpPnKEH-DVYeRr69l_B7Jflh_SthK_S.zip\n"
     ]
    }
   ],
   "source": [
    "fileId = '1-XpPnKEH-DVYeRr69l_B7Jflh_SthK_S'\n",
    "\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "from shutil import copy\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "fileName = fileId + '.zip'\n",
    "downloaded = drive.CreateFile({'id': fileId})\n",
    "downloaded.GetContentFile(fileName)\n",
    "ds = ZipFile(fileName)\n",
    "ds.extractall()\n",
    "os.remove(fileName)\n",
    "print('Extracted zip file ' + fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VWTTn5p2HjOD"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score,precision_score,recall_score,accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "U3pbia2HHku7",
    "outputId": "ef29dd98-0716-4404-986f-60a491ca3bbb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "#import cv2\n",
    "import json\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import colors\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "n25pwQKHHmAy",
    "outputId": "516a8b73-de1f-4089-e442-ed7661c2ac61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adc.json\tsample_data\t\t   Train_data\n",
      "cat_levels.csv\tTIL_sample_submission.csv  Train_data.csv\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kKotgO_YHoNk"
   },
   "outputs": [],
   "source": [
    "import dask.dataframe as pd2\n",
    "loc0 = (r'/content/Train_data/Train_data.csv')\n",
    "#train = pd2.read_csv(loc0,error_bad_lines=False,sep='|',warn_bad_lines=False,assume_missing=True,chunksize=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FjSo8fFrHpje"
   },
   "outputs": [],
   "source": [
    "#loc0 = (r'/content/Train_data.csv')\n",
    "loc1 = (r'/content/cat_levels.csv')\n",
    "#train = pd.read_csv(loc0, error_bad_lines=False)\n",
    "levels = pd.read_csv(loc1, error_bad_lines=False)\n",
    "loc2 = (r'/content/TIL_sample_submission.csv')\n",
    "sample = pd.read_csv(loc2, error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "colab_type": "code",
    "id": "VBG0KqhtHqzC",
    "outputId": "af7241e7-83b6-44af-ea15-5a9701d34f3c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category_tree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21047</td>\n",
       "      <td>entertainment-&gt;bollywood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21047</td>\n",
       "      <td>News &amp; Politics -&gt; Politics -&gt; bjp -&gt; dharmend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>243958</td>\n",
       "      <td>sports -&gt; Outdoor Games - &gt; Tennis -&gt; novak dj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>243958</td>\n",
       "      <td>location -&gt; serbia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                      category_tree\n",
       "0   21047                           entertainment->bollywood\n",
       "1   21047  News & Politics -> Politics -> bjp -> dharmend...\n",
       "2  243958  sports -> Outdoor Games - > Tennis -> novak dj...\n",
       "3  243958                                 location -> serbia"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "colab_type": "code",
    "id": "Xsi4ljDBHsPa",
    "outputId": "ea51cce4-bf04-4166-f695-4fce8b20e9b1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level1_categories</th>\n",
       "      <th>level_2_categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Info Tech</td>\n",
       "      <td>Info Tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Travel &amp; Tourism</td>\n",
       "      <td>PaaS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Travel</td>\n",
       "      <td>Products</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vehicles &amp; Parts</td>\n",
       "      <td>SaaS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Automobiles</td>\n",
       "      <td>Travel &amp; Tourism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>NaN</td>\n",
       "      <td>CAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Click</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>NaN</td>\n",
       "      <td>DFP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Impression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Solar Energy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    level1_categories level_2_categories\n",
       "0           Info Tech          Info Tech\n",
       "1    Travel & Tourism               PaaS\n",
       "2              Travel           Products\n",
       "3    Vehicles & Parts               SaaS\n",
       "4         Automobiles   Travel & Tourism\n",
       "..                ...                ...\n",
       "157               NaN                CAN\n",
       "158               NaN              Click\n",
       "159               NaN                DFP\n",
       "160               NaN         Impression\n",
       "161               NaN       Solar Energy\n",
       "\n",
       "[162 rows x 2 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levels[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "FK9WR7EbHWkO",
    "outputId": "064e8736-6d52-472d-b5e2-2b3ec7a007de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting googletrans\n",
      "  Downloading https://files.pythonhosted.org/packages/fd/f0/a22d41d3846d1f46a4f20086141e0428ccc9c6d644aacbfd30990cf46886/googletrans-2.4.0.tar.gz\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from googletrans) (2.23.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->googletrans) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->googletrans) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->googletrans) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->googletrans) (2020.4.5.1)\n",
      "Building wheels for collected packages: googletrans\n",
      "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for googletrans: filename=googletrans-2.4.0-cp36-none-any.whl size=15777 sha256=51b819825f85f00c0ca21806ba6646891d6d5f2fb30cb9c651d51acecd646662\n",
      "  Stored in directory: /root/.cache/pip/wheels/50/d6/e7/a8efd5f2427d5eb258070048718fa56ee5ac57fd6f53505f95\n",
      "Successfully built googletrans\n",
      "Installing collected packages: googletrans\n",
      "Successfully installed googletrans-2.4.0\n"
     ]
    }
   ],
   "source": [
    "pip install googletrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "6IauFsnGHbbi",
    "outputId": "29ac661e-064c-4754-f23b-f46fb92c3b29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
      "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
      "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
      "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
      "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
      "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
      "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
      "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
      "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
      "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
      "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
      "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
      "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
      "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
      "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
      "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
      "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
      "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
      "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
      "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
      "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
      "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
      "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
      "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/names.zip.\n",
      "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
      "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
      "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
      "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
      "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
      "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
      "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
      "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
      "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
      "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
      "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
      "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
      "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
      "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
      "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
      "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
      "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
      "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
      "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
      "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
      "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
      "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
      "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
      "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
      "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
      "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
      "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/words.zip.\n",
      "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
      "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
      "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
      "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping\n",
      "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
      "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
      "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    }
   ],
   "source": [
    "from googletrans import Translator\n",
    "import nltk\n",
    "nltk.download('all')\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Mzfj7_FVVXrb",
    "outputId": "5f068d76-a730-49c6-e901-23bce2a95dca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n",
      "1000\n",
      "1010\n",
      "1020\n",
      "1030\n",
      "1040\n",
      "1050\n",
      "1060\n",
      "1070\n",
      "1080\n",
      "1090\n",
      "1100\n",
      "1110\n",
      "1120\n",
      "1130\n",
      "1140\n",
      "1150\n",
      "1160\n",
      "1170\n",
      "1180\n",
      "1190\n",
      "1200\n",
      "1210\n",
      "1220\n",
      "1230\n",
      "1240\n",
      "1250\n",
      "1260\n",
      "1270\n",
      "1280\n",
      "1290\n",
      "1300\n",
      "1310\n",
      "1320\n",
      "1330\n",
      "1340\n",
      "1350\n",
      "1360\n",
      "1370\n",
      "1380\n",
      "1390\n",
      "1400\n",
      "1410\n",
      "1420\n",
      "1430\n",
      "1440\n",
      "1450\n",
      "1460\n",
      "1470\n",
      "1480\n",
      "1490\n",
      "1500\n",
      "1510\n",
      "1520\n",
      "1530\n",
      "1540\n",
      "1550\n",
      "1560\n",
      "1570\n",
      "1580\n",
      "1590\n",
      "1600\n",
      "1610\n",
      "1620\n",
      "1630\n",
      "1640\n",
      "1650\n",
      "1660\n",
      "1670\n",
      "1680\n",
      "1690\n",
      "1700\n",
      "1710\n",
      "1720\n",
      "1730\n",
      "1740\n",
      "1750\n",
      "1760\n",
      "1770\n",
      "1780\n",
      "1790\n",
      "1800\n",
      "1810\n",
      "1820\n",
      "1830\n",
      "1840\n",
      "1850\n",
      "1860\n",
      "1870\n",
      "1880\n",
      "1890\n",
      "1900\n",
      "1910\n",
      "1920\n",
      "1930\n",
      "1940\n",
      "1950\n",
      "1960\n",
      "1970\n",
      "1980\n",
      "1990\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "list4=[]\n",
    "dd=-1\n",
    "id_=[]\n",
    "tree = []\n",
    "for chunk in pd.read_csv(loc0,sep='|', chunksize=1):\n",
    "  if(dd ==2000):\n",
    "    break\n",
    "  dd=dd+1\n",
    "  if(dd%10==0):\n",
    "    print(dd)\n",
    "  if(chunk.shape[1]!=5):\n",
    "    continue\n",
    "  chunk.iloc[0][1] = chunk.iloc[0][1].replace(\"/\", \" \")\n",
    "  chunk.iloc[0][1] = chunk.iloc[0][1].replace(\".\", \" \")\n",
    "  chunk.iloc[0][1] = chunk.iloc[0][1].replace(\"-\", \" \")\n",
    "  sw = stopwords.words('english')\n",
    "  list3=[]\n",
    "  list2=[]\n",
    "  for j in range (0,32):     \n",
    "    Y_list = word_tokenize(levels['level1_categories'][j].lower())\n",
    "    Y_set = {w for w in Y_list if not w in sw} \n",
    "\n",
    "    z=0\n",
    "\n",
    "    for jj in range(0,4):\n",
    "#      if(len(chunk.iloc[0][jj])==0):\n",
    "#        continue\n",
    "      X_list = word_tokenize(str(chunk.iloc[0][jj]).lower()) \n",
    "      X_set = {w for w in X_list if not w in sw}\n",
    "    \n",
    "      q=0\n",
    "#    z=0    \n",
    "#      list1=[]\n",
    "      for word1 in X_set:\n",
    "       for word2 in Y_set:\n",
    "         if(len(wordnet.synsets(word1))):\n",
    "           wordFromList1 = wordnet.synsets(word1)[0]\n",
    "         else:\n",
    "           continue\n",
    "         if(len(wordnet.synsets(word2))):\n",
    "           wordFromList2 = wordnet.synsets(word2)[0]\n",
    "         else:\n",
    "           continue\n",
    "         q =  wordFromList1.wup_similarity(wordFromList2)\n",
    "         if(q!=None):\n",
    "          z=z+q\n",
    "  #        list1.append(q)\n",
    "    list2.append(z)\n",
    "#    if(z>45):\n",
    "#      if(levels['level1_categories'][j] == 'Info Tech' and z>32):\n",
    "#        list3.append(levels['level1_categories'][j])\n",
    "#      elif(levels['level1_categories'][j] != 'Info Tech'):\n",
    "#        list3.append(levels['level1_categories'][j])\n",
    "  if(len(list3)==0):\n",
    "    max_v = 0\n",
    "    max_i = 0\n",
    "    for uu in range(0,32):\n",
    "      if(list2[uu]>max_v):\n",
    "        max_v=list2[uu]\n",
    "        max_i=uu\n",
    "    list3.append(levels['level1_categories'][max_i])\n",
    "\n",
    "\n",
    "  for j in range (0,len(levels)):     \n",
    "    Y_list = word_tokenize(levels['level_2_categories'][j].lower())\n",
    "    Y_set = {w for w in Y_list if not w in sw} \n",
    "\n",
    "    z=0\n",
    "\n",
    "    for jj in range(0,4):\n",
    "#      if(len(chunk.iloc[0][jj])==0):\n",
    "#        continue\n",
    "      X_list = word_tokenize(str(chunk.iloc[0][jj]).lower()) \n",
    "      X_set = {w for w in X_list if not w in sw}\n",
    "    \n",
    "      q=0\n",
    "#    z=0    \n",
    "#      list1=[]\n",
    "      for word1 in X_set:\n",
    "       for word2 in Y_set:\n",
    "         if(len(wordnet.synsets(word1))):\n",
    "           wordFromList1 = wordnet.synsets(word1)[0]\n",
    "         else:\n",
    "           continue\n",
    "         if(len(wordnet.synsets(word2))):\n",
    "           wordFromList2 = wordnet.synsets(word2)[0]\n",
    "         else:\n",
    "           continue\n",
    "         q =  wordFromList1.wup_similarity(wordFromList2)\n",
    "         if(q!=None):\n",
    "          z=z+q\n",
    "  #        list1.append(q)\n",
    "    list2.append(z)\n",
    "  if(len(list3)==1):\n",
    "    max_v = 0\n",
    "    max_i = 0\n",
    "    for uu in range(0,len(levels)):\n",
    "      if(list2[uu]>max_v):\n",
    "        max_v=list2[uu]\n",
    "        max_i=uu\n",
    " #   list3.append(levels['level_2_categories'][max_i])\n",
    "    list3[0] = list3[0] + ' -> ' + levels['level_2_categories'][max_i]\n",
    "\n",
    "\n",
    "  list4.append(list3)\n",
    "  id_.append(chunk.iloc[0][4])\n",
    "#print(q)\n",
    "#print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212
    },
    "colab_type": "code",
    "id": "bCGuwdTUQnaU",
    "outputId": "64fa6ae8-c759-4812-913d-1ca21f813650"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8.913842890855276,\n",
       " 6.517153177060298,\n",
       " 3.2585765885301488,\n",
       " 8.123231996761408,\n",
       " 3.286611135682343,\n",
       " 3.0646304675716447,\n",
       " 6.517153177060298,\n",
       " 0,\n",
       " 7.211132984662394,\n",
       " 3.479070929070929,\n",
       " 6.467390942390944]"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "colab_type": "code",
    "id": "Z4ap3e_aXs6-",
    "outputId": "5042a9cb-3b81-4eae-d212-f4d2eee280ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Music and Audio -> News'],\n",
       " ['Vehicles & Parts -> Education'],\n",
       " ['Vehicles & Parts -> Education'],\n",
       " ['Career & Job -> Religion & Spirituality'],\n",
       " ['Family and Relationships -> Religion & Spirituality'],\n",
       " ['Career & Job -> Religion & Spirituality'],\n",
       " ['Real Estate -> Religion & Spirituality'],\n",
       " ['Music and Audio -> News'],\n",
       " ['Music and Audio -> Religion & Spirituality'],\n",
       " ['Music and Audio -> Religion & Spirituality']]"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list4[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "V-sgjqdxM5Gg",
    "outputId": "ad6eae7e-a38f-4df9-c168-c835a61d6714"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2674,\n",
       " 3874,\n",
       " 425,\n",
       " 5177,\n",
       " 3260,\n",
       " 1867,\n",
       " 4988,\n",
       " 2882,\n",
       " 2675,\n",
       " 2058,\n",
       " 2676,\n",
       " 3875,\n",
       " 0,\n",
       " 2481,\n",
       " 1262,\n",
       " 4615,\n",
       " 4616,\n",
       " 4229,\n",
       " 629,\n",
       " 3261,\n",
       " 3677,\n",
       " 6523,\n",
       " 3476]"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VeSW3SByWwEF"
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['id'] = id_\n",
    "sub['category_tree'] = list4\n",
    "sub['category_tree'] = sub['category_tree'].str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "rd4q1my4ZGUn",
    "outputId": "7e894463-e06e-4885-bba7-911669ff6274",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category_tree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2674</td>\n",
       "      <td>Music and Audio -&gt; News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3874</td>\n",
       "      <td>Vehicles &amp; Parts -&gt; Education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>425</td>\n",
       "      <td>Vehicles &amp; Parts -&gt; Education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5177</td>\n",
       "      <td>Career &amp; Job -&gt; Religion &amp; Spirituality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3260</td>\n",
       "      <td>Family and Relationships -&gt; Religion &amp; Spiritu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1867</td>\n",
       "      <td>Career &amp; Job -&gt; Religion &amp; Spirituality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4988</td>\n",
       "      <td>Real Estate -&gt; Religion &amp; Spirituality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2882</td>\n",
       "      <td>Music and Audio -&gt; News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2675</td>\n",
       "      <td>Music and Audio -&gt; Religion &amp; Spirituality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2058</td>\n",
       "      <td>Music and Audio -&gt; Religion &amp; Spirituality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2676</td>\n",
       "      <td>Music and Audio -&gt; Religion &amp; Spirituality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3875</td>\n",
       "      <td>Family and Relationships -&gt; Religion &amp; Spiritu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>Career &amp; Job -&gt; Religion &amp; Spirituality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2481</td>\n",
       "      <td>Vehicles &amp; Parts -&gt; Religion &amp; Spirituality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1262</td>\n",
       "      <td>Career &amp; Job -&gt; Religion &amp; Spirituality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4615</td>\n",
       "      <td>Vehicles &amp; Parts -&gt; Religion &amp; Spirituality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4616</td>\n",
       "      <td>Career &amp; Job -&gt; Religion &amp; Spirituality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4229</td>\n",
       "      <td>Career &amp; Job -&gt; Religion &amp; Spirituality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>629</td>\n",
       "      <td>Vehicles &amp; Parts -&gt; Religion &amp; Spirituality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3261</td>\n",
       "      <td>Family and Relationships -&gt; Religion &amp; Spiritu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3677</td>\n",
       "      <td>Music and Audio -&gt; Religion &amp; Spirituality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6523</td>\n",
       "      <td>Vehicles &amp; Parts -&gt; Education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3476</td>\n",
       "      <td>Home &amp; Garden -&gt; News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4810</td>\n",
       "      <td>Career &amp; Job -&gt; Religion &amp; Spirituality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3063</td>\n",
       "      <td>Real Estate -&gt; Religion &amp; Spirituality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>630</td>\n",
       "      <td>Family and Relationships -&gt; Religion &amp; Spiritu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6329</td>\n",
       "      <td>Music and Audio -&gt; Religion &amp; Spirituality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5766</td>\n",
       "      <td>Vehicles &amp; Parts -&gt; Religion &amp; Spirituality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4068</td>\n",
       "      <td>Sports &amp; Games -&gt; Religion &amp; Spirituality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4617</td>\n",
       "      <td>Music and Audio -&gt; Religion &amp; Spirituality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3064</td>\n",
       "      <td>Vehicles &amp; Parts -&gt; Education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3678</td>\n",
       "      <td>Vehicles &amp; Parts -&gt; Religion &amp; Spirituality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>4811</td>\n",
       "      <td>Family and Relationships -&gt; Religion &amp; Spiritu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>6893</td>\n",
       "      <td>Career &amp; Job -&gt; Religion &amp; Spirituality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>426</td>\n",
       "      <td>Music and Audio -&gt; Religion &amp; Spirituality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2253</td>\n",
       "      <td>Music and Audio -&gt; Religion &amp; Spirituality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>4989</td>\n",
       "      <td>Family and Relationships -&gt; Religion &amp; Spiritu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>6524</td>\n",
       "      <td>Family and Relationships -&gt; Religion &amp; Spiritu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>4413</td>\n",
       "      <td>Personal Finance -&gt; Religion &amp; Spirituality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>4812</td>\n",
       "      <td>Real Estate -&gt; Religion &amp; Spirituality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>6894</td>\n",
       "      <td>Vehicles &amp; Parts -&gt; Religion &amp; Spirituality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>5178</td>\n",
       "      <td>Family and Relationships -&gt; Religion &amp; Spiritu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>3065</td>\n",
       "      <td>Music and Audio -&gt; Religion &amp; Spirituality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>846</td>\n",
       "      <td>Music and Audio -&gt; Religion &amp; Spirituality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>5767</td>\n",
       "      <td>Music and Audio -&gt; Religion &amp; Spirituality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>5957</td>\n",
       "      <td>Career &amp; Job -&gt; Religion &amp; Spirituality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1048</td>\n",
       "      <td>Vehicles &amp; Parts -&gt; Religion &amp; Spirituality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1263</td>\n",
       "      <td>Career &amp; Job -&gt; Religion &amp; Spirituality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>3066</td>\n",
       "      <td>Sports &amp; Games -&gt; Religion &amp; Spirituality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>5550</td>\n",
       "      <td>Travel &amp; Tourism -&gt; Religion &amp; Spirituality</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                      category_tree\n",
       "0   2674                            Music and Audio -> News\n",
       "1   3874                      Vehicles & Parts -> Education\n",
       "2    425                      Vehicles & Parts -> Education\n",
       "3   5177            Career & Job -> Religion & Spirituality\n",
       "4   3260  Family and Relationships -> Religion & Spiritu...\n",
       "5   1867            Career & Job -> Religion & Spirituality\n",
       "6   4988             Real Estate -> Religion & Spirituality\n",
       "7   2882                            Music and Audio -> News\n",
       "8   2675         Music and Audio -> Religion & Spirituality\n",
       "9   2058         Music and Audio -> Religion & Spirituality\n",
       "10  2676         Music and Audio -> Religion & Spirituality\n",
       "11  3875  Family and Relationships -> Religion & Spiritu...\n",
       "12     0            Career & Job -> Religion & Spirituality\n",
       "13  2481        Vehicles & Parts -> Religion & Spirituality\n",
       "14  1262            Career & Job -> Religion & Spirituality\n",
       "15  4615        Vehicles & Parts -> Religion & Spirituality\n",
       "16  4616            Career & Job -> Religion & Spirituality\n",
       "17  4229            Career & Job -> Religion & Spirituality\n",
       "18   629        Vehicles & Parts -> Religion & Spirituality\n",
       "19  3261  Family and Relationships -> Religion & Spiritu...\n",
       "20  3677         Music and Audio -> Religion & Spirituality\n",
       "21  6523                      Vehicles & Parts -> Education\n",
       "22  3476                              Home & Garden -> News\n",
       "23  4810            Career & Job -> Religion & Spirituality\n",
       "24  3063             Real Estate -> Religion & Spirituality\n",
       "25   630  Family and Relationships -> Religion & Spiritu...\n",
       "26  6329         Music and Audio -> Religion & Spirituality\n",
       "27  5766        Vehicles & Parts -> Religion & Spirituality\n",
       "28  4068          Sports & Games -> Religion & Spirituality\n",
       "29  4617         Music and Audio -> Religion & Spirituality\n",
       "30  3064                      Vehicles & Parts -> Education\n",
       "31  3678        Vehicles & Parts -> Religion & Spirituality\n",
       "32  4811  Family and Relationships -> Religion & Spiritu...\n",
       "33  6893            Career & Job -> Religion & Spirituality\n",
       "34   426         Music and Audio -> Religion & Spirituality\n",
       "35  2253         Music and Audio -> Religion & Spirituality\n",
       "36  4989  Family and Relationships -> Religion & Spiritu...\n",
       "37  6524  Family and Relationships -> Religion & Spiritu...\n",
       "38  4413        Personal Finance -> Religion & Spirituality\n",
       "39  4812             Real Estate -> Religion & Spirituality\n",
       "40  6894        Vehicles & Parts -> Religion & Spirituality\n",
       "41  5178  Family and Relationships -> Religion & Spiritu...\n",
       "42  3065         Music and Audio -> Religion & Spirituality\n",
       "43   846         Music and Audio -> Religion & Spirituality\n",
       "44  5767         Music and Audio -> Religion & Spirituality\n",
       "45  5957            Career & Job -> Religion & Spirituality\n",
       "46  1048        Vehicles & Parts -> Religion & Spirituality\n",
       "47  1263            Career & Job -> Religion & Spirituality\n",
       "48  3066          Sports & Games -> Religion & Spirituality\n",
       "49  5550        Travel & Tourism -> Religion & Spirituality"
      ]
     },
     "execution_count": 85,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pKoUaZOVufX3",
    "outputId": "5c056046-63c2-44ae-bd7d-39567b4184c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2001"
      ]
     },
     "execution_count": 81,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BMdqzk7MZILX"
   },
   "outputs": [],
   "source": [
    "sub.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n8YcW72rdLqZ"
   },
   "outputs": [],
   "source": [
    "# This block is only relevant if you are running this notebook on Google Colab\n",
    "from google.colab import files\n",
    "files.download('submission.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Rishabh.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
